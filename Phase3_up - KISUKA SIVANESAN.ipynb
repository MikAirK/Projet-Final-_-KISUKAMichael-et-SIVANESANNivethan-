{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Filière :* ING3 - Tronc commun\n",
    "\n",
    "*Auteurs :*\n",
    "**Michael KISUKA** et\n",
    "**Nivethan SIVANESAN**\n",
    "\n",
    "*Professeur référent :* \n",
    "**TAJINI Badr**\n",
    "\n",
    "*Année :* 2024-2025\n",
    "\n",
    "**ESIEE-IT**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8dc732",
   "metadata": {},
   "source": [
    "\n",
    "# Phase 3 : Construction et Entraînement d'un Modèle MLP\n",
    "\n",
    "Dans cette phase, nous allons construire un modèle de réseau de neurones multicouches (MLP) en utilisant **scikit-learn**.  \n",
    "Nous allons ensuite l'entraîner sur le dataset **MNIST** et évaluer ses performances.\n",
    "\n",
    "### Objectifs :\n",
    "1. Charger et prétraiter les données MNIST.\n",
    "2. Construire un modèle MLP simple avec scikit-learn.\n",
    "3. Entraîner le modèle et mesurer sa précision.\n",
    "4. Observer quelques prédictions effectuées par le modèle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle MLP créé : MLPClassifier(hidden_layer_sizes=(50,), max_iter=10, random_state=42)\n",
      "\n",
      "Début de l'entraînement du modèle...\n",
      "Entraînement terminé.\n",
      "\n",
      "Précision du modèle sur l'ensemble de test : 96.46%\n",
      "\n",
      "Quelques prédictions et étiquettes réelles :\n",
      "Image 1: Prédiction = 8, Réel = 8\n",
      "Image 2: Prédiction = 4, Réel = 4\n",
      "Image 3: Prédiction = 8, Réel = 8\n",
      "Image 4: Prédiction = 7, Réel = 7\n",
      "Image 5: Prédiction = 7, Réel = 7\n",
      "Image 6: Prédiction = 0, Réel = 0\n",
      "Image 7: Prédiction = 6, Réel = 6\n",
      "Image 8: Prédiction = 2, Réel = 2\n",
      "Image 9: Prédiction = 7, Réel = 7\n",
      "Image 10: Prédiction = 4, Réel = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# 1. Charger le dataset MNIST\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X = mnist.data.astype(np.float32) / 255.0  # Normaliser les données\n",
    "y = mnist.target.astype(int)\n",
    "\n",
    "# 2. Diviser les données en ensembles d'entraînement et de test\n",
    "#    C'est crucial pour évaluer les performances du modèle sur des données qu'il n'a jamais vues.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Construire un modèle MLP (vous pouvez utiliser un des modèles de l'étape 2 ou en créer un nouveau)\n",
    "#    Commençons par un modèle simple pour l'entraînement initial.\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(50,), max_iter=10, random_state=42)\n",
    "print(\"Modèle MLP créé :\", mlp)\n",
    "\n",
    "# 4. Entraîner le modèle sur les données d'entraînement\n",
    "#    C'est là que le modèle apprend à reconnaître les chiffres.\n",
    "print(\"\\nDébut de l'entraînement du modèle...\")\n",
    "mlp.fit(X_train, y_train)\n",
    "print(\"Entraînement terminé.\")\n",
    "\n",
    "# 5. Faire des prédictions sur l'ensemble de test\n",
    "#    Utiliser le modèle entraîné pour prédire les chiffres sur l'ensemble de test.\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "# 6. Évaluer les performances du modèle en calculant la précision\n",
    "#    La précision mesure le pourcentage de chiffres correctement classifiés.\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nPrécision du modèle sur l'ensemble de test : {accuracy * 100:.2f}%\")\n",
    "\n",
    "# 7. (Facultatif) Afficher quelques prédictions et les étiquettes réelles pour comparaison\n",
    "print(\"\\nQuelques prédictions et étiquettes réelles :\")\n",
    "for i in range(10):\n",
    "    print(f\"Image {i+1}: Prédiction = {y_pred[i]}, Réel = {y_test.iloc[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir que le processus prend un certain temps à se mettre en marche car il prend le temps de traiter toutes les images. On voit que sur l'ensemble du test, la précision du modèle est à peu près à 96.46% ce qui est très proche de 100%.\n",
    "\n",
    "Si on s'attarde sur les résultats, on se rend compte que pour chaque image, notre modèle propose une prédication sous forme de chiffre et qu'au final lors du resultat final, on voit que la prédication était vrai et que la logique de notre modèle à été confirmé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle MLP créé : MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=50, random_state=42)\n",
      "\n",
      "Début de l'entraînement du modèle...\n",
      "Entraînement terminé.\n",
      "\n",
      "Précision du modèle sur l'ensemble de test : 97.55%\n",
      "\n",
      "Quelques prédictions et étiquettes réelles :\n",
      "Image 1: Prédiction = 8, Réel = 8\n",
      "Image 2: Prédiction = 4, Réel = 4\n",
      "Image 3: Prédiction = 8, Réel = 8\n",
      "Image 4: Prédiction = 7, Réel = 7\n",
      "Image 5: Prédiction = 7, Réel = 7\n",
      "Image 6: Prédiction = 0, Réel = 0\n",
      "Image 7: Prédiction = 6, Réel = 6\n",
      "Image 8: Prédiction = 2, Réel = 2\n",
      "Image 9: Prédiction = 7, Réel = 7\n",
      "Image 10: Prédiction = 4, Réel = 4\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# 1. Charger le dataset MNIST\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X = mnist.data.astype(np.float32) / 255.0  # Normaliser les données\n",
    "y = mnist.target.astype(int)\n",
    "\n",
    "# 2. Diviser les données en ensembles d'entraînement et de test\n",
    "#    C'est crucial pour évaluer les performances du modèle sur des données qu'il n'a jamais vues.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Construire un modèle MLP (vous pouvez utiliser un des modèles de l'étape 2 ou en créer un nouveau)\n",
    "#    Commençons par un modèle simple pour l'entraînement initial.\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=50, random_state=42)\n",
    "print(\"Modèle MLP créé :\", mlp)\n",
    "\n",
    "# 4. Entraîner le modèle sur les données d'entraînement\n",
    "#    C'est là que le modèle apprend à reconnaître les chiffres.\n",
    "print(\"\\nDébut de l'entraînement du modèle...\")\n",
    "mlp.fit(X_train, y_train)\n",
    "print(\"Entraînement terminé.\")\n",
    "\n",
    "# 5. Faire des prédictions sur l'ensemble de test\n",
    "#    Utiliser le modèle entraîné pour prédire les chiffres sur l'ensemble de test.\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "# 6. Évaluer les performances du modèle en calculant la précision\n",
    "#    La précision mesure le pourcentage de chiffres correctement classifiés.\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nPrécision du modèle sur l'ensemble de test : {accuracy * 100:.2f}%\")\n",
    "\n",
    "# 7. (Facultatif) Afficher quelques prédictions et les étiquettes réelles pour comparaison\n",
    "print(\"\\nQuelques prédictions et étiquettes réelles :\")\n",
    "for i in range(10):\n",
    "    print(f\"Image {i+1}: Prédiction = {y_pred[i]}, Réel = {y_test.iloc[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour améliorer la précision du modèle, deux modifications principales peuvent être apportées. La première consiste à augmenter le nombre d'itérations d'entraînement en ajustant le paramètre max_iter. En augmentant cette valeur, le modèle a plus de temps pour apprendre les motifs dans les données, ce qui peut améliorer la précision. Par exemple, en passant de max_iter=10 à max_iter=50 ou max_iter=100, on peut observer une meilleure performance. Cependant, il faut faire attention au surapprentissage, où le modèle mémorise trop les données d'entraînement et devient moins efficace sur des données nouvelles.\n",
    "\n",
    "Modifier l'architecture du réseau en augmentant le nombre de neurones ou en ajoutant des couches cachées (hidden_layer_sizes) permet d'affiner la capacité du modèle à reconnaître des motifs complexes. Une architecture plus profonde améliore les performances, mais une complexité excessive peut nuire à la généralisation. L'objectif est de trouver un équilibre entre précision et efficacité.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Les résultats avant et après la modification du code montrent une amélioration notable dans la performance du modèle de classification MLP appliqué aux données MNIST. Dans la version initiale, le modèle utilise un réseau de neurones avec une seule couche cachée de 50 neurones et un nombre d'itérations limité à 10, ce qui limite la capacité d'apprentissage et, par conséquent, la précision du modèle. Après modification, l'architecture du modèle a été ajustée pour inclure une couche cachée de 100 neurones, suivie d'une autre de 50, et le nombre d'itérations a été augmenté à 50. Ces ajustements permettent au modèle d'apprendre de manière plus approfondie, ce qui se reflète dans une meilleure précision sur l'ensemble de test. En somme, la modification du code permet au modèle d'atteindre des performances accrues en offrant une plus grande capacité d'apprentissage et un entraînement plus long."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
